{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import *\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_nan(tup):\n",
    "    return([None] if len(tup[0]) == 0 else tup[0])\n",
    "\n",
    "def get_indexes_match(l1, l2):\n",
    "\n",
    "    return([return_nan(np.where([x in e for x in l2])) for e in l1])\n",
    "\n",
    "def merge(df1, df2, left_on, right_on):\n",
    "    df1.loc[:, 'idx'] = get_indexes_match(df1[left_on].values,\n",
    "                                          df2[right_on].values)\n",
    "    \n",
    "def clean_keywords(keyword):\n",
    "    return re.sub('[^.,a-zA-Z0-9 \\n\\.]', '', str(keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on year 1999 file whose size is (7435, 6)\n",
      "(5771, 7)\n",
      "Working on year 2000 file whose size is (28219, 6)\n",
      "(24713, 7)\n",
      "Working on year 2001 file whose size is (30392, 6)\n",
      "(25162, 7)\n",
      "Working on year 2002 file whose size is (45837, 6)\n",
      "(39016, 7)\n",
      "Working on year 2003 file whose size is (101843, 6)\n",
      "(79366, 7)\n",
      "Working on year 2004 file whose size is (137578, 6)\n",
      "(110847, 7)\n",
      "Working on year 2005 file whose size is (162273, 6)\n",
      "(132716, 7)\n",
      "Working on year 2006 file whose size is (185204, 6)\n",
      "(150490, 7)\n",
      "Working on year 2007 file whose size is (198805, 6)\n",
      "(156831, 7)\n",
      "Working on year 2008 file whose size is (214291, 6)\n",
      "(166655, 7)\n",
      "Working on year 2009 file whose size is (222319, 6)\n",
      "(174119, 7)\n",
      "Working on year 2010 file whose size is (250374, 6)\n",
      "(187402, 7)\n",
      "Working on year 2011 file whose size is (266933, 6)\n",
      "(200781, 7)\n",
      "Working on year 2012 file whose size is (266726, 6)\n",
      "(198553, 7)\n",
      "Working on year 2013 file whose size is (268266, 6)\n",
      "(190512, 7)\n",
      "Working on year 2014 file whose size is (330570, 6)\n",
      "(244212, 7)\n",
      "Working on year 2015 file whose size is (365130, 6)\n",
      "(274880, 7)\n",
      "Working on year 2016 file whose size is (407139, 6)\n",
      "(308943, 7)\n",
      "Working on year 2017 file whose size is (428026, 6)\n",
      "(329788, 7)\n",
      "Working on year 2018 file whose size is (456926, 6)\n",
      "(354744, 7)\n",
      "Working on year 2019 file whose size is (436112, 6)\n",
      "(339953, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1999, 2020):\n",
    "    File= pd.read_csv(\"/Users/kamakshibansal/Moorfields/Symptoms.csv\")\n",
    "    File[\"Symptoms\"]= File[\"Symptoms\"].str.lower()\n",
    "\n",
    "    \n",
    "    \n",
    "    FileL = pd.read_csv(\"/Users/kamakshibansal/Moorfields/Letters/Anonymised/Letters_new_{}.csv\".format(i))\n",
    "    FileL=FileL.dropna()\n",
    "    print (\"Working on year {} file whose size is\".format(i), FileL.shape)\n",
    "\n",
    "    FileL[\"LetterBody\"]= FileL[\"LetterBody\"].str.lower()\n",
    "    \n",
    "    FileL=FileL[~FileL.LetterBody.str.contains(\"was discharged\" and \"postoperative\" and \"discharge\")]\n",
    "    \n",
    "    merge(FileL, File, left_on='LetterBody', right_on='Symptoms')\n",
    "    \n",
    "    File[\"Symptoms\"] = File.values.tolist()\n",
    "    FileL['Symptoms'] = FileL.idx.apply(lambda x: [File[\"Symptoms\"].get(i) for i in x])\n",
    "\n",
    "    FileL['Symptoms2'] = FileL.Symptoms.map(clean_keywords)\n",
    "    FileL= FileL.drop([\"Symptoms\",\"idx\"], axis=1)\n",
    "\n",
    "    File_Symp= FileL[FileL['Symptoms2']!=\"None\"]\n",
    "    \n",
    "    print(File_Symp.shape)\n",
    "    \n",
    "    File_Symp.to_csv(\"/Users/kamakshibansal/Moorfields/Letters/Filtered_Symptoms/File_withsymptoms{}.csv\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3778334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5849+ 25110 + 25746+ 39705+  81573+ 113389+ 135857+ 154695+ 160990 + 171223+ 178393+ 191664+ 204442+ 203602+ 197817+ 251570 + 281393+  315449+ 335447+ 359563+ 344857  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4810398"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7435+ 28219+ 30392+ 45837 + 101843+ 137578+ 162273+ 185204+ 198805+ 214291+ 222319+ 250374+ 266933+ 266726+ 268266+ 330570+ 365130+ 407139+ 428026+ 456926+ 436112   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
